{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eye color classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_directory = 'dataset/train/eyes'\n",
    "test_data_directory = 'dataset/test/eyes'\n",
    "\n",
    "import cv2 # open cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "load_model = tf.keras.models.load_model\n",
    "image = tf.keras.preprocessing.image\n",
    "ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator\n",
    "Sequential = tf.keras.models.Sequential\n",
    "Dense = tf.keras.layers.Dense\n",
    "Activation = tf.keras.layers.Activation\n",
    "Flatten = tf.keras.layers.Flatten\n",
    "Conv2D = tf.keras.layers.Conv2D\n",
    "MaxPooling2D = tf.keras.layers.MaxPooling2D\n",
    "\n",
    "picture_width = 400\n",
    "picture_height = 540\n",
    "\n",
    "CLASSES = ['black','blue','brown']\n",
    "MODEL_NAME = 'eyes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 74 images belonging to 3 classes.\n",
      "Found 29 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# initiate data preprocessing tools\n",
    "\n",
    "# This step processes the images into a format that\n",
    "# 1. makes the data readable to the model\n",
    "# 2. provides more training material for the model to train from\n",
    "# the `training_data_processor` below scales the data so that it can be\n",
    "# a model input, but also takes each image and augments it so that\n",
    "# the model can learn from multiple variations of the same image.\n",
    "# it flips it horizontally, rotates it, shifts it, and more so that \n",
    "# the model learns from the soil photo rather than the orientation size\n",
    "training_data_processor  = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip = True,\n",
    "    zoom_range = 0.2,\n",
    "    rotation_range = 10,\n",
    "    shear_range = 0.2,\n",
    "    height_shift_range = 0.1,\n",
    "    width_shift_range = 0.1,\n",
    ")\n",
    "# for the testing images, we don't need to create multiple variatinos\n",
    "test_data_processor = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# load data into python\n",
    "\n",
    "training_data = training_data_processor.flow_from_directory(\n",
    "    train_data_directory,\n",
    "    target_size = (picture_width, picture_height), # pixels\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical',\n",
    ")\n",
    "\n",
    "testing_data = test_data_processor.flow_from_directory(\n",
    "    test_data_directory,\n",
    "    target_size = (picture_width, picture_height),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 11s 3s/step - loss: 1.3142 - accuracy: 0.2838 - val_loss: 1.1409 - val_accuracy: 0.3448\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 9s 4s/step - loss: 1.1282 - accuracy: 0.3784 - val_loss: 1.1077 - val_accuracy: 0.3448\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 11s 3s/step - loss: 1.0932 - accuracy: 0.3784 - val_loss: 1.0947 - val_accuracy: 0.3448\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 11s 3s/step - loss: 1.0644 - accuracy: 0.4189 - val_loss: 1.0527 - val_accuracy: 0.4828\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 11s 5s/step - loss: 1.0377 - accuracy: 0.5000 - val_loss: 1.0035 - val_accuracy: 0.4828\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 12s 3s/step - loss: 1.0101 - accuracy: 0.4324 - val_loss: 0.9544 - val_accuracy: 0.6207\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.9918 - accuracy: 0.5270 - val_loss: 1.3155 - val_accuracy: 0.3793\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.9709 - accuracy: 0.5541 - val_loss: 0.8895 - val_accuracy: 0.5862\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.9272 - accuracy: 0.5405 - val_loss: 0.9511 - val_accuracy: 0.5517\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.8921 - accuracy: 0.6622 - val_loss: 0.8219 - val_accuracy: 0.6207\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 10s 4s/step - loss: 0.8693 - accuracy: 0.6351 - val_loss: 0.7781 - val_accuracy: 0.6207\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.7346 - accuracy: 0.6892 - val_loss: 0.7964 - val_accuracy: 0.5862\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 10s 4s/step - loss: 0.6892 - accuracy: 0.7162 - val_loss: 0.7477 - val_accuracy: 0.6207\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.6631 - accuracy: 0.7297 - val_loss: 0.7457 - val_accuracy: 0.6552\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 10s 4s/step - loss: 0.7398 - accuracy: 0.6216 - val_loss: 0.7558 - val_accuracy: 0.6897\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.8335 - accuracy: 0.6216 - val_loss: 0.7580 - val_accuracy: 0.6897\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.8870 - accuracy: 0.6486 - val_loss: 0.8481 - val_accuracy: 0.6207\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.7727 - accuracy: 0.6081 - val_loss: 0.8003 - val_accuracy: 0.5862\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.6534 - accuracy: 0.7297 - val_loss: 0.7163 - val_accuracy: 0.7586\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.6470 - accuracy: 0.7297 - val_loss: 0.7203 - val_accuracy: 0.6207\n"
     ]
    }
   ],
   "source": [
    "# choose model parameters\n",
    "num_conv_layers = 3\n",
    "num_dense_layers = 2\n",
    "layer_size = 29 # limit the layer size as we dont want to over fit the model\n",
    "num_training_epochs = 25\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# begin adding properties to model variable\n",
    "# e.g. add a convulutional layer\n",
    "model.add(Conv2D(layer_size, (3,3), input_shape=(picture_width, picture_height, 3)))\n",
    "model.add(Activation('relu')) # rectified linear unit\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# add additional convolutional layers based on num_conv_layers\n",
    "for _ in range(num_conv_layers-1):\n",
    "    model.add(Conv2D(layer_size, (3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# reduce dimensionality\n",
    "model.add(Flatten())\n",
    "\n",
    "# add fully connected \"dense\" layers if specified\n",
    "for _ in range(num_dense_layers):\n",
    "    model.add(Dense(layer_size))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(len(CLASSES)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# compile the sequential model with all added properties\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# use the data already loaded to train/tune the model\n",
    "model.fit(\n",
    "    training_data, \n",
    "    epochs = num_training_epochs, \n",
    "    validation_data = testing_data)\n",
    "\n",
    "# save the trained model\n",
    "model.save(f'{MODEL_NAME}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 897ms/step - loss: 0.6411 - accuracy: 0.7162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6411091685295105, 0.7162162065505981]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(training_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
